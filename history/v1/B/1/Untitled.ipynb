{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile \n",
    "from torchvision import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "\n",
    "                      \n",
    "%matplotlib inline  \n",
    "\n",
    "# Set PIL to be tolerant of image files that are truncated.\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    " # Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    " \n",
    "# Location of data\n",
    "dog_file='../../dogImages/'\n",
    "\n",
    "# train=os.path.join(dog_file,'train')\n",
    "valid=os.path.join(dog_file,'valid')\n",
    "test=os.path.join(dog_file,'test')\n",
    "\n",
    "train = f'{dog_file}/train'\n",
    "\n",
    "# Datasets from each folder\n",
    "train_file=datasets.ImageFolder(train,transform=image_transforms['train'])\n",
    "valid_file=datasets.ImageFolder(valid,transform=image_transforms['valid'])\n",
    "test_file=datasets.ImageFolder(test,transform=image_transforms['test'])\n",
    "\n",
    "\n",
    "# To avoid loading all of the data into memory at once, I used training DataLoaders. First, I created \n",
    "# a dataset object from the image folders, and then I passed these to a DataLoader. \n",
    "# At training time, the DataLoader will load the images from disk, apply the transformations, \n",
    "# and yield a batch. To train and validation, we'll iterate through all the batches in the respective \n",
    "# DataLoader.\n",
    "# One crucial aspect is to shuffle the data before passing it to the network. \n",
    "# This means that the ordering of the image categories changes on each pass through the data \n",
    "# (one pass through the data is one training epoch).\n",
    "\n",
    "\n",
    "\n",
    "loaders={\n",
    "    'train':torch.utils.data.DataLoader(train_file,batch_size,shuffle=True),\n",
    "    'valid':torch.utils.data.DataLoader(valid_file,batch_size,shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(test_file,batch_size,shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(loaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 20,  41,  16,  84, 105,  95,  11,  34,  81,  14,  22,  50,  56, 129,\n",
       "        105, 100,  91, 127,  78,  62,  61,  45, 128,  70,  90,  24,  56,  16,\n",
       "         52,  35,  80,  24])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_data_dir = '../../dogImages'\n",
    "human_data_dir = 'lfw'\n",
    "\n",
    "def get_data_dir(is_dog):\n",
    "    \n",
    "    data_dir = dog_data_dir if is_dog else human_data_dir\n",
    "    \n",
    "    if not is_dog:\n",
    "        return {\n",
    "        'train_dir': data_dir,\n",
    "        'valid_dir': data_dir,\n",
    "        'test_dir': data_dir\n",
    "    }\n",
    "    \n",
    "    train_dir = data_dir + '/train'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    test_dir = data_dir + '/test'\n",
    "    \n",
    "    return {\n",
    "        'train_dir': train_dir,\n",
    "        'valid_dir': valid_dir,\n",
    "        'test_dir': test_dir\n",
    "    }\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation((0, 360)),\n",
    "                                       transforms.RandomResizedCrop(224),              \n",
    "                                       transforms.ToTensor(),  \n",
    "                                       normalize])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.RandomRotation((0, 360)),\n",
    "                                       transforms.RandomResizedCrop(224),              \n",
    "                                       transforms.ToTensor(),  \n",
    "                                       normalize])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256), \n",
    "                                       transforms.CenterCrop(224),              \n",
    "                                       transforms.ToTensor(), \n",
    "                                       normalize])\n",
    "\n",
    "def get_data_loaders(is_dog, batch_sizes=[32, 32, 32]):\n",
    "    \n",
    "    data_dir_dict = get_data_dir(is_dog)\n",
    "    \n",
    "    train_dir = data_dir_dict['train_dir']\n",
    "    valid_dir = data_dir_dict['valid_dir']\n",
    "    test_dir = data_dir_dict['test_dir']\n",
    "    \n",
    "    train_data = datasets.ImageFolder(train, transform=train_transforms)\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_file,batch_size,shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_sizes[1])\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_sizes[2])\n",
    "    \n",
    "    return {\n",
    "        'train': train_loader,\n",
    "        'valid': valid_loader,\n",
    "        'test': test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8,  87, 117,  79,  90,  36,   0,  58,  20, 100,  89,  88, 130,  55,\n",
       "         97,  27, 100,  13,  76,  18,  95,  37,  20,  20,  81,  55, 115, 111,\n",
       "         82,  42, 125, 111])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = next(iter(get_data_loaders(True)['train']))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
